{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3asgXMqnSGPE",
        "outputId": "a22d001a-b29d-41eb-c0e8-707a046afd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## Train a tf.keras model for CIFAR without clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w7Fd6jZ7SGPL",
        "outputId": "c2a855d0-ae41-4778-a0a7-208765f31bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 31s 21ms/step - loss: 1.6241 - accuracy: 0.4303 - val_loss: 1.4221 - val_accuracy: 0.5114\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 28s 20ms/step - loss: 1.3768 - accuracy: 0.5196 - val_loss: 1.3429 - val_accuracy: 0.5388\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.3064 - accuracy: 0.5433 - val_loss: 1.3042 - val_accuracy: 0.5540\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.2539 - accuracy: 0.5654 - val_loss: 1.2815 - val_accuracy: 0.5668\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2082 - accuracy: 0.5796 - val_loss: 1.2829 - val_accuracy: 0.5620\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1661 - accuracy: 0.5954 - val_loss: 1.2301 - val_accuracy: 0.5796\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 29s 20ms/step - loss: 1.1353 - accuracy: 0.6080 - val_loss: 1.1794 - val_accuracy: 0.5978\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 29s 20ms/step - loss: 1.1042 - accuracy: 0.6203 - val_loss: 1.1926 - val_accuracy: 0.5912\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 28s 20ms/step - loss: 1.0843 - accuracy: 0.6241 - val_loss: 1.2187 - val_accuracy: 0.5794\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.0665 - accuracy: 0.6318 - val_loss: 1.1546 - val_accuracy: 0.6044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd7f4c4dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Load cifar dataset\n",
        "cifar = keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images  = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32,3)),\n",
        "    keras.layers.Reshape(target_shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### Evaluate the baseline model and save it for later usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HYulekocSGPP",
        "outputId": "46537b03-1366-43a5-ca0e-c1a7e2ca693f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.5928000211715698\n",
            "Saving model to:  /tmp/tmpqp7g5y1m.h5\n"
          ]
        }
      ],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## Fine-tune the pre-trained model with clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "Apply the `cluster_weights()` API to a whole pre-trained model to demonstrate its effectiveness in reducing the model size after applying zip while keeping decent accuracy. For how best to balance the accuracy and compression rate for your use case, please refer to the per layer example in the [comprehensive guide](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_comprehensive_guide).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "### Define the model and apply the clustering API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOB5vjOZMTS"
      },
      "source": [
        "Before you pass the model to the clustering API, make sure it is trained and shows some acceptable accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OzqKKt0mSGPT",
        "outputId": "8d233244-0b34-4d06-a79c-780d7034945d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cluster_reshape_1 (ClusterW  (None, 32, 32, 3)        0         \n",
            " eights)                                                         \n",
            "                                                                 \n",
            " cluster_conv2d_1 (ClusterWe  (None, 30, 30, 12)       676       \n",
            " ights)                                                          \n",
            "                                                                 \n",
            " cluster_max_pooling2d_1 (Cl  (None, 15, 15, 12)       0         \n",
            " usterWeights)                                                   \n",
            "                                                                 \n",
            " cluster_flatten_1 (ClusterW  (None, 2700)             0         \n",
            " eights)                                                         \n",
            "                                                                 \n",
            " cluster_dense_1 (ClusterWei  (None, 10)               54026     \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,702\n",
            "Trainable params: 27,378\n",
            "Non-trainable params: 27,324\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 16,\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
        "}\n",
        "\n",
        "# Cluster a whole model\n",
        "clustered_model = cluster_weights(model, **clustering_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning clustered model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "clustered_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "clustered_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev4MyClmSGPW"
      },
      "source": [
        "### Fine-tune the model and evaluate the accuracy against baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoy9CcASGPX"
      },
      "source": [
        "Fine-tune the model with clustering for 1 epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jn29-coXSGPX",
        "outputId": "68472086-bda9-437e-f439-7a0b50a40132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 22s 239ms/step - loss: 1.2016 - accuracy: 0.5844 - val_loss: 1.2698 - val_accuracy: 0.5684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd7f64ba00>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Fine-tune model\n",
        "clustered_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  batch_size=500,\n",
        "  epochs=1,\n",
        "  validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvaZKoxtTORx"
      },
      "source": [
        "For this example, there is minimal loss in test accuracy after clustering, compared to the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bE7MxpWLTaQ1",
        "outputId": "87d874fd-881d-47c5-95fe-ea0e24eb3d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.5953999757766724\n",
            "Clustered test accuracy: 0.5616999864578247\n"
          ]
        }
      ],
      "source": [
        "_, clustered_model_accuracy = clustered_model.evaluate(\n",
        "  test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Clustered test accuracy:', clustered_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXfPMa6ISGPd"
      },
      "source": [
        "## Create **6x** smaller models from clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zr_QIhcUeuC"
      },
      "source": [
        "Both `strip_clustering` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression benefits of clustering. \n",
        "\n",
        "First, create a compressible model for TensorFlow. Here, `strip_clustering` removes all variables (e.g. `tf.Variable` for storing the cluster centroids and the indices) that clustering only needs during training, which would otherwise add to model size during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4h6tSvMzSGPd",
        "outputId": "1d7f884c-7858-46de-f7f1-2b2fcd764888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving clustered model to:  /tmp/tmp9qgebgfe.h5\n"
          ]
        }
      ],
      "source": [
        "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
        "\n",
        "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving clustered model to: ', clustered_keras_file)\n",
        "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
        "                           include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZcotzPSVBtu"
      },
      "source": [
        "Then, create compressible models for TFLite. You can convert the clustered model to a format that's runnable on your targeted backend. TensorFlow Lite is an example you can use to deploy to mobile devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v2N47QW6SGPh",
        "outputId": "c27b9f5e-3236-4cf2-b0c9-8dc36a0bbd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved clustered TFLite model to: /tmp/clustered_cifar.tflite\n"
          ]
        }
      ],
      "source": [
        "clustered_tflite_file = '/tmp/clustered_cifar.tflite'\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "tflite_clustered_model = converter.convert()\n",
        "with open(clustered_tflite_file, 'wb') as f:\n",
        "  f.write(tflite_clustered_model)\n",
        "print('Saved clustered TFLite model to:', clustered_tflite_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7amG_9XV-w9"
      },
      "source": [
        "Define a helper function to actually compress the models via gzip and measure the zipped size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1XJ4QBMpW5JB"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INeAOWRBSGPj"
      },
      "source": [
        "Compare and see that the models are **6x** smaller from clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SG1MgZCeSGPk",
        "outputId": "7fc023d4-d69a-49a6-e21f-d81bb978bb21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 104080.00 bytes\n",
            "Size of gzipped clustered Keras model: 16105.00 bytes\n",
            "Size of gzipped clustered TFlite model: 15283.00 bytes\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
        "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOgpEGfSGPn"
      },
      "source": [
        "## Create an **8x** smaller TFLite model from combining weight clustering and post-training quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQb50aC3SGPn"
      },
      "source": [
        "You can apply post-training quantization to the clustered model for additional benefits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XyHC8euLSGPo",
        "outputId": "005d8f30-fae0-4199-9e07-2fdd6c4fd165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved quantized and clustered TFLite model to: /tmp/tmpzeshlxoq.tflite\n",
            "Size of gzipped baseline Keras model: 104080.00 bytes\n",
            "Size of gzipped clustered and quantized TFlite model: 11738.00 bytes\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-yBcocGSGPv"
      },
      "source": [
        "## See the persistence of accuracy from TF to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_pcf0XSGPv"
      },
      "source": [
        "Define a helper function to evaluate the TFLite model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EJ9B7pRISGPw"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0swuxbPmSGPy"
      },
      "source": [
        "You evaluate the model, which has been clustered and quantized, and then see the accuracy from TensorFlow persists to the TFLite backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RFD4LXjpSGPz",
        "outputId": "abbe325f-6a65-4bf2-afa5-1a86b2b2b082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Clustered and quantized TFLite test_accuracy: 0.1\n",
            "Clustered TF test accuracy: 0.5616999864578247\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Clustered TF test accuracy:', clustered_model_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "clustering_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}